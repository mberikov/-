{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHusTRntgTMS6oI00xSwDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mberikov/Classification-of-Exhaled-Breath-Absorption-Spectra-Using-Machine-Learning-Methods/blob/main/Classification_of_Exhaled_Breath_Absorption_Spectra_Using_Machine_Learning_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtFZ-PI6DHy4"
      },
      "outputs": [],
      "source": [
        "# импортируем библиотеки\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.optimize as spo\n",
        "import math\n",
        "\n",
        "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from numpy.polynomial import Polynomial\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmap1 = ListedColormap(['blue','orange']) #создаём два графика, который будет показывать синие и оранжевые компаненты\n",
        "cmap2 = ListedColormap(['green','red'])\n",
        "\n",
        "def sigmoid(x, L, x0, k, b):\n",
        "    y = L / (1 + np.exp(-k*(x - x0))) + b # сигмоидальная функция\n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "cm = 1/2.54 # перевод в см обратные"
      ],
      "metadata": {
        "id": "ilu4PIx9DSOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "поиск спектров молекул в папке path и копирование от туда данных\n",
        "\n",
        "\"\"\"\n",
        "path = 'Gas_comp'\n",
        "pathCompon = [] #установка пути к папке и инициализация переменных\n",
        "\n",
        "nameCompon = os.listdir(path) #получение списка файлов в папке\n",
        "\n",
        "for i in nameCompon:\n",
        "    i = (path) + \"/\" + (i)\n",
        "    pathCompon.append(i) #Формирование полных путей к файлам\n",
        "\n",
        "df = pd.read_csv(pathCompon[0], sep=\"\\t\", usecols=[0], names=[\"wavenumber\"]) #Чтение первого файла и создание DataFrame\n",
        "\n",
        "for a, b in zip(pathCompon, nameCompon):\n",
        "    a = pd.read_csv(a, sep=\"\\t\", usecols=[0, 1], names=[\"wavenumber\", b]) #Объединение данных из всех файлов\n",
        "    df = df.merge(a) # JOIN\n",
        "\n",
        "wavenumber = df['wavenumber'].values #извлечение значений\n",
        "del df['wavenumber'] # удаление обьекта столбца у длины волны  #столбец wavenumber удаляется из DataFrame df, оставляя только данные, относящиеся к другим компонентам.\n",
        "\n",
        "df_coef = np.zeros((1, len(nameCompon))) #\n",
        "df_coef = pd.DataFrame(df_coef, columns = nameCompon)#\n",
        "\n",
        "\"\"\"\n",
        "конец\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "H4KPOHsgDSd-",
        "outputId": "70860408-1e00-47e8-d872-c720d758919e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'lib64' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4033f729d088>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpathCompon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnameCompon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnameCompon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lib64' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#хз зачем добавил\n",
        "\"\"\"\n",
        "тут мы будем задавать коэфиценты\n",
        "\"\"\"\n",
        "\n",
        "def Coef_create(name_com = []):\n",
        "        name = name_com[::3]\n",
        "        num = name_com[1::3]\n",
        "        df_coef_copy = df_coef.copy()\n",
        "\n",
        "        if len(name_com) != 0:\n",
        "            for a, b in zip(name, num):  #\n",
        "                df_coef_copy[a][0] = b # Для каждой пары a и b значение b присваивается в строку с индексом 0 и столбец с именем a в DataFrame df_coef_copy. Это означает, что в первой строке DataFrame df_coef_copy обновляются значения на основе переданных данных\n",
        "            return df_coef_copy.values\n",
        "        else:\n",
        "            print(\"не указаны значения\")\n",
        "\n",
        "\"\"\"\n",
        "конец\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eJ5SP6SnVhE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "тут мы создаем смесь\n",
        "\"\"\"\n",
        "\n",
        "def Mix(data = list, name_com = [] ,name_num = []):\n",
        "\n",
        "    if len(data) != 0:\n",
        "        data0 = data[0]\n",
        "        data1 = data[1]\n",
        "    else:\n",
        "        data0 = []\n",
        "\n",
        "    name = name_num[0::3] # извлекает элементы из списка name_num, начиная с индекса 0 и выбирая каждый третий элемент.\n",
        "    var1 = name_num[1::3]\n",
        "    var2 = name_num[2::3]\n",
        "\n",
        "    if len(name_com) != 0:\n",
        "        arr_coef = Coef_create(name_com) # Если name_com содержит значения, то функция Coef_create будет вызвана, и результат будет сохранен в arr_coef\n",
        "    else:\n",
        "        print(\"нету заданных данных\")"
      ],
      "metadata": {
        "id": "iy1bb33AI4RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # тутц\n",
        "    arr_coefall = np.array([])\n",
        "    for a, b in zip(var1, var2):\n",
        "        arr_coef1 = np.random.uniform(a, b, size=(1, 100))  # В этой строке генерируем массив arr_coef1, который содержит 100 случайных чисел, равномерно распределенных между a и b. Размер массива — (1, 100), что означает, что это двумерный массив с одной строкой и 100 столбцами.\n",
        "\n",
        "        if len(arr_coefall) == 0:\n",
        "            arr_coefall = arr_coef1\n",
        "        else:\n",
        "            arr_coefall = np.vstack((arr_coefall, arr_coef1)) # объединяем массивы"
      ],
      "metadata": {
        "id": "oUIJo8mwDStP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   # тутц\n",
        "    arr_coefall = arr_coefall.T"
      ],
      "metadata": {
        "id": "cnsnoL6GDS5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # тутц\n",
        "    df_coef_copy = df_coef.copy() #копирую\n",
        "    df_coef_copy = pd.concat([df_coef]*100, ignore_index=True) #создаю 100 повторений df_coef увеличивая df_coef_copy, объединяя её"
      ],
      "metadata": {
        "id": "aig7HI15DTIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# тутц\n",
        "\n",
        "    for a, b in zip(name, range(0, len(name))):\n",
        "\n",
        "        df_coef_copy[a] = arr_coefall[:,b]"
      ],
      "metadata": {
        "id": "zS30P0ZKDTSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # матричное произведение коэфицентов компонент на интенсивности компонент\n",
        "    df_pre = np.dot(df.values, df_coef_copy.values.T)\n",
        "\n",
        "    # именование концентраций\n",
        "    name_mix = ''\n",
        "    for a, b in zip(name, var1):\n",
        "        name_mix = name_mix + f'{a}:{b} ' # name:var1\n",
        "    name_mix = name_mix[:-1] #удаляю пробел в последней строчке\n",
        "\n",
        "    # добовление имени с концентрациями в список data0\n",
        "    data0.append(f'спектр с концентрациями {name_mix}')\n",
        "\n",
        "    # добавлени данных смеси в список data1\n",
        "    if len(data) != 0:\n",
        "        data1 = np.hstack((data1, df_pre))\n",
        "    else:\n",
        "        data1 = df_pre\n",
        "\n",
        "    # добавление списков data1 и data0 в общий список data\n",
        "    data = [data0, data1]\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "конец\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qkxw5_SZDTne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calcul(pre_data, numcompon = 0, begin_wave = int ,end_wave = int, z = float):\n",
        "    name_id = pre_data[0]\n",
        "    df = pre_data[1]\n",
        "\n",
        "    if numcompon != 0:\n",
        "        pca = PCA(numcompon) #с количеством компонент\n",
        "        df_Pca = pca.fit_transform(df[begin_wave:end_wave,:]) #Новые измерения для выборки\n",
        "\n",
        "\n",
        "    else:\n",
        "        pca = PCA()\n",
        "        df_Pca = pca.fit_transform(df[begin_wave:end_wave,:]) # Новые измерения для выборки\n",
        "\n",
        "    df_score = pca.components_\n",
        "    df_score = df_score.T\n",
        "\n",
        "\n",
        "\n",
        "    h = str(z).replace('.',',')\n",
        "    # тут мы создаем дефолтные графики счетов\n",
        "    for i in range(1,3):\n",
        "\n",
        "        plt.scatter(df_score[100*(i-1):100*i,0],df_score[100*(i-1):100*i,2])\n",
        "\n",
        "    plt.xlabel('PC1')\n",
        "    plt.ylabel('PC3')\n",
        "    plt.savefig(fname=f'C:/Users/Maksim/Desktop/project_dip/graph_{begin_wave}-{end_wave}_wave/PCA/shym_{h}.png')\n",
        "    plt.show()\n",
        "\n",
        "    return df_score\n",
        "\"\"\"\n",
        "конец\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IlfNI1ubDTz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "шум и SVM\n",
        "\"\"\"\n",
        "\n",
        "def shym_SVM(data, begin_wave, end_wave):\n",
        "\n",
        "    sd_Sensitivity = [] # mean чувствитеьность\n",
        "    sd_Specificity = [] # mean спецификация\n",
        "\n",
        "    shym = np.linspace(0.00000001, 0.004, 20)\n",
        "    std_Sensitivity = []\n",
        "    std_Specificity = []\n",
        "\n",
        "    for z in shym:\n",
        "\n",
        "        newdata = [e.copy() for e in data]\n",
        "        newdata[1] = newdata[1] + (z *np.random.normal(0, 0.5, size=(newdata[1].shape)))\n",
        "        a = calcul(newdata, 0 , begin_wave, end_wave, z) # закидываем копию данных с шумом\n",
        "\n",
        "        # метод опрорных векторов\n",
        "        Sensitivity = [] # чувствитеьность\n",
        "        Specificity = [] # спецификация\n",
        "\n",
        "        y = np.zeros(200)\n",
        "        y[:100] = y[:100] - 1\n",
        "        y[100:] = y[100:] + 1\n",
        "\n",
        "\n",
        "        for i in range (0, 1000):\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(a[:,:3:2], y, test_size = 0.3) #разделяем выборку на обучающаюся и тестовую (в пропорции 70% на 30%)\n",
        "\n",
        "            clf = svm.SVC(kernel = 'sigmoid') #Делаю SVM, ипсользуя тип ядра сигмоидальной функции\n",
        "            clf.fit(X_train, y_train) # обучаю\n",
        "\n",
        "            y_pred = clf.predict(X_test) #тест\n",
        "\n",
        "            \"\"\"\n",
        "            tn (true negatives): доля истинно отрицательных предсказаний.\n",
        "            fp (false positives): доля ложных положительных предсказаний.\n",
        "            fn (false negatives): доля ложных отрицательных предсказаний.\n",
        "            tp (true positives): доля истинно положительных предсказаний\n",
        "            \"\"\"\n",
        "\n",
        "            tn, fp, fn, tp = confusion_matrix(y_test, y_pred, normalize='true').ravel() #матрица ошибок y_test - истинные метки, y_pred - предсказанные, ravel - приводим к одномерному виду, чтобы его потом разбить\n",
        "            Sensitivity.append((tp/(tp + fn))) #чисор больных, выявленных классификатором деленное на истинное число больных, среди тестируемой выборки\n",
        "            Specificity.append((tn/(tn + fp))) #число здоровых, выявленных классификатором деленное на истинное число здоровых, среди тестируемой выборки\n",
        "\n",
        "\n",
        "        sd_Sensitivity.append(np.mean(Sensitivity))\n",
        "        sd_Specificity.append(np.mean(Specificity))\n",
        "\n",
        "        std_Sensitivity.append(np.std(Sensitivity))\n",
        "        std_Specificity.append(np.std(Sensitivity))\n",
        "\n",
        "\n",
        "        mask1 = (y_test==1)\n",
        "        mask2 = (y_test==-1)\n",
        "        ax = plt.gca()\n",
        "        ax.scatter(X_test[mask1,0], X_test[mask1,1], label='здоровые',edgecolors='black',c=['green'])\n",
        "        ax.scatter(X_test[mask2,0], X_test[mask2,1], label='болеющие раком легких',edgecolors='black', c=['red'])\n",
        "        ax.legend()\n",
        "        xlim = ax.get_xlim()\n",
        "        ylim = ax.get_ylim()\n",
        "\"\"\"\n",
        "np.meshgrid() принимает эти линейные массивы и создает две двумерные матрицы (xx и yy), где каждая точка соответствует координатам в пространстве. Это необходимо для построения графиков, где нужно знать координаты всех точек в сет\n",
        "\"\"\"\n",
        "        xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 100), np.linspace(ylim[0], ylim[1], 100)) #создает двумерные массивы координат, которые используются для визуализации решений классификатора\n",
        "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) #объединение кординат из xx и yy в одномерный массив, где каждую строку представляется (x,y) координаты.  clf.predict - предсказания классов на основе координат (x,y). Классификатор clf возвращает массив классов для каждой точки в сетке\n",
        "        Z = Z.reshape(xx.shape)\n",
        "\n",
        "        contours = plt.contour(xx, yy, Z, levels=[0], linewidths=3, linestyles='dashed') # linestyles - пунктир\n",
        "        plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.4)  #cmap=plt.cm.Paried задаёт цветовую карту\n",
        "\n",
        "\n",
        "        plt.scatter(X_test[mask1,0], X_test[mask1,1], label='здоровые',edgecolors='black',c=['green'])\n",
        "        plt.scatter(X_test[mask2,0], X_test[mask2,1], label='болеющие раком легких',edgecolors='black',c=['red'])\n",
        "        plt.xlabel('PC1')\n",
        "        plt.ylabel('PC3')\n",
        "\n",
        "        plt.title(f'на спектральном диапазоне от {wavenumber[begin_wave]} см^-1 до {wavenumber[end_wave]} см^-1')\n",
        "\n",
        "\n",
        "        plt.savefig(fname=f'C:/Users/Maksim/Desktop/project_dip/graph_{begin_wave}-{end_wave}_wave/SVM/shym_{z}.png')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "-F5WDr8TDUGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " sd_Sensitivity = np.array(sd_Sensitivity)\n",
        "    sd_Specificity = np.array(sd_Specificity)\n",
        "    std_Sensitivity = np.array(std_Sensitivity)\n",
        "    std_Specificity = np.array(std_Specificity)\n",
        "\n",
        "    print('***********')\n",
        "    print(f'шум = {shym[6]}, на частотном диапазоне - от {wavenumber[begin_wave]} см^-1 до {wavenumber[end_wave]} см^-1')\n",
        "    print(f'чувствительность среднее - {sd_Sensitivity[6]} ,дисперсия - {std_Sensitivity[6]}')\n",
        "    print(f'спецефичность среднее - {sd_Specificity[6]} ,дисперсия - {std_Specificity[6]}')\n",
        "    print('***********')\n",
        "    # отрисовка чувствительности и специфичности\n",
        "\n",
        "    fig, axs = plt.subplots(figsize=(20*cm, 10*cm), nrows=1, ncols=2, layout=\"tight\")# фигура с подграфиками, layout - оптимальное расположение на графики(чтобы не было перекрытия)\n",
        "\n",
        "    popt, _ = spo.curve_fit(sigmoid, shym, sd_Sensitivity,  maxfev=30000) #подгонка кривой sigmoid  к данным шума и средней чувствительности, maxfev - max интерраций\n",
        "    L_fit, x0_fit, k_fit, b_fit = popt # содержит найденные параметры для функции sigmoid, которые присваиваются переменным\n",
        "\n",
        "\n",
        "    axs[0].plot(shym, sigmoid(shym, L_fit, x0_fit, k_fit, b_fit)*100) #умножаю на 100, чтобы было в %\n",
        "    axs[0].errorbar(shym, sigmoid(shym, L_fit, x0_fit, k_fit, b_fit)*100, std_Sensitivity*100, ls=' ', marker='x', capsize=2.5, elinewidth=1, color='black')\n",
        "\n",
        "\"\"\"\"\n",
        "spo.curve_fit: Это функция из библиотеки scipy.optimize, которая используется для подгонки функции к данным. Она минимизирует сумму квадратов разностей между наблюдаемыми значениями и значениями, предсказанными моделью\n",
        "\"\"\"\n",
        "    popt, _ = spo.curve_fit(sigmoid, shym, sd_Specificity,  maxfev=30000)\n",
        "    L_fit, x0_fit, k_fit, b_fit = popt\n",
        "\n",
        "    axs[1].plot(shym, sigmoid(shym, L_fit, x0_fit, k_fit, b_fit)*100)\n",
        "    axs[1].errorbar(shym, sigmoid(shym, L_fit, x0_fit, k_fit, b_fit)*100, std_Specificity*100, ls=' ', marker='x', capsize=2.5, elinewidth=1, color='black')\n",
        "\n",
        "\n",
        "    axs[0].set_xlabel('шум, см^-1')\n",
        "    axs[0].set_ylabel('Sensitivity, %')\n",
        "    axs[1].set_xlabel('шум, см^-1')\n",
        "    axs[1].set_ylabel('Specificity, %')\n",
        "\n",
        "    fig.legend(['ср. значение', 'ср. кв. откланение'], fontsize=8,loc='center', bbox_to_anchor=(0.9, 0.82))\n",
        "    fig.suptitle(f'Sensitivity и Specificity на спектральном диапазоне от {wavenumber[begin_wave]} см^-1 до {wavenumber[end_wave]} см^-1')\n",
        "    plt.savefig(fname=f'C:/Users/Maksim/Desktop/project_dip/graph_{begin_wave}-{end_wave}_wave/sens&spec.png')\n",
        "    plt.show()\n",
        "    del fig, axs"
      ],
      "metadata": {
        "id": "j6a2EUKxDUVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "# df_coef['H2O'] = 0.03\n",
        "# df_coef['CO2'] = 0.04\n",
        "\n",
        "# задаем смеси, которые мы измерили у 100 человек типа больных и 100 здоровых\n",
        "data = Mix(data ,[],[\n",
        "'H2O', 0.05, 0.06,\n",
        "'CO2', 0.03, 0.05,\n",
        "'CO', 1*10**-6, 10**-5,\n",
        "'NO', 1000*10**-9, 3500*10**-9,\n",
        "'NH3', 1*10**-9, 1000*10**-9,\n",
        "'CH3OH', 0.02*10**-6, 1.09*10**-6,\n",
        "'CH3CN', 0.2*10**-6, 0.37*10**-6,\n",
        "'CH4',30*10**-6,100*10**-6,\n",
        "'C2H4',1*10**-9,100*10**-9\n",
        "])\n",
        "\n",
        "data = Mix(data ,[],[\n",
        "'H2O', 0.05, 0.06,\n",
        "'CO2', 0.03, 0.05,\n",
        "'CO', 0.1*10**-6, 6*10**-6,\n",
        "'NO', 3*10**-9, 1000*10**-9,\n",
        "'NH3', 1*10**-9, 500*10**-9,\n",
        "'CH3OH', 1*10**-9, 10*10**-9,\n",
        "'CH3CN', 0.2*10**-6, 0.21*10**-6,\n",
        "'CH4',1.5*10**-6,3*10**-6,\n",
        "'C2H4',1*10**-9,30*10**-9\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "x=np.array([0,1,2,3])\n",
        "\n",
        "for i in 2**x:\n",
        "\n",
        "wave_list = []\n",
        "wave_step = (wavenumber.shape[0]-1)/i\n",
        "v = 0\n",
        "while v != (wavenumber.shape[0]-1):\n",
        "wave_list.append(v)\n",
        "wave_list.append(v)\n",
        "v = v + wave_step\n",
        "\n",
        "wave_list.append((wavenumber.shape[0]-1))\n",
        "wave_list = [int(item) for item in wave_list]\n",
        "wave_list.pop(0)\n",
        "\n",
        "\n",
        "for j, k in zip(wave_list[0::2],wave_list[1::2]):\n",
        "\n",
        "shym_SVM(data, j, k)\n",
        "\n",
        "\n",
        "plt.plot(wavenumber,data[1][:,0:100])\n",
        "plt.xticks([wavenumber[0], wavenumber[1262], wavenumber[2525], wavenumber[3787], wavenumber[5050], wavenumber[6312], wavenumber[7575], wavenumber[8837], wavenumber[10100]])"
      ],
      "metadata": {
        "id": "pkihBU0Zqz2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "RAFYVfv0DUiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EmRx8M2HDTcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iwd26-sWWIuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_5k2zHcWI-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KIDX4mWzWJL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zrXum5hJWJbS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}